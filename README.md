# ðŸ‘‹ Jack's AI & LLMOps Portfolio

**One central hub for production-grade AI knowledge**  
**Kenya-based AI/ML Engineer & Technical Author** | Open to remote MLOps, AI Platform, LLMOps, and AI Documentation roles (2026)

[![GitHub Pages](https://img.shields.io/badge/Portfolio-Live-brightgreen)](https://jacksteve-code.github.io/)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://linkedin.com/in/YOUR-PROFILE)
[![Email](https://img.shields.io/badge/Email-jack@yourdomain.com-red)](mailto:jack@yourdomain.com)

---

## ðŸŽ¯ About Me

I am a passionate **AI/ML Engineer and Technical Author** based in **Ruiru, Kenya**, with a deep focus on turning cutting-edge AI research into reliable, scalable, and production-ready systems.

Over the past years I have built and documented complete end-to-end blueprints that real engineering teams actually use:

- Full **LLMOps pipelines** that go from prompt to production monitoring
- **Federated Learning** architectures that respect privacy and data sovereignty
- Deep technical breakdowns of the evolution from RNNs â†’ Transformers
- Practical **AI Infrastructure & Compute Optimization** strategies
- The shifting role of technical writers in the age of AI co-authors

All my guides are **open-source, battle-tested in structure**, and written from the perspective of someone who has to ship AI systems that donâ€™t break at 3 a.m.

I created this central portfolio so recruiters, engineers, and fellow AI practitioners can discover everything Iâ€™ve built in one place.

---

## ðŸ“š Featured Technical Guides (2025â€“2026)

### 1. **Scalable LLMOps Pipeline** â€” 46 pages
**The most comprehensive production LLMOps reference currently available on GitHub Pages.**

**What youâ€™ll learn:**
- Full end-to-end architecture (Foundations â†’ Build â†’ Deploy â†’ Observe â†’ Scale)
- Prompt registry, RAG optimization, LangChain/LangGraph orchestration
- Observability stack (LangSmith, Helicone, Phoenix)
- Guardrails, A/B testing, canary releases, cost optimization & multi-model routing
- Real-world enterprise example stack (LangChain + Pinecone + OpenAI + Kubernetes)

**Perfect for:** MLOps engineers, LLM application developers, and platform teams moving from prototype to production.

**[â†’ Read the full 46-page guide](https://jacksteve-code.github.io/Scalable-llmop/)**

---

### 2. **Federated Learning Blueprint** â€” 38 pages
**Production-grade architecture for privacy-preserving collaborative AI.**

**Covers:**
- Cross-device & cross-silo FL (FedAvg, FedProx, hierarchical variants)
- Security & privacy deep dive (Differential Privacy, SMPC, Homomorphic Encryption)
- Defenses against poisoning, inference, and model extraction attacks
- Integration with Flower, FedML, NVIDIA FLARE, PyTorch/TensorFlow
- Heterogeneity handling, communication compression, drift detection

**Target audience:** Privacy engineers, healthcare/finance AI teams, edge AI practitioners.

**[â†’ Read the full 38-page blueprint](https://jacksteve-code.github.io/federated-blueprint/)**

---

### 3. **AI Infrastructure & Compute Optimization** â€” 38 pages
**From theory to real-world cost & performance wins.**

**Key sections:**
- Training vs Inference workload dichotomy
- Hardware deep dive (GPUs, TPUs, NVLink, InfiniBand)
- Software stack optimization (mixed precision, quantization, XLA, Triton kernels)
- Distributed training strategies, model parallelism, pipeline parallelism
- Cost modeling and energy efficiency at scale

**Ideal for:** ML platform engineers, infra teams, and anyone tired of burning money on GPUs.

**[â†’ Read the full 38-page guide](https://jacksteve-code.github.io/AI-Infrastructure-and-compute-optimization/)**

---

### 4. **RNNs to Transformers** â€” 23 pages (with full PyTorch code)
**Mathematical & code-level journey from recurrent networks to modern attention.**

**Includes:**
- Vanilla RNN â†’ LSTM â†’ GRU â†’ full Transformer architecture
- Backpropagation Through Time, vanishing/exploding gradients
- Complete character-level RNN implementation in PyTorch
- Why the Transformer won (parallelism, long-range dependencies)

**Best for:** Students, engineers brushing up on fundamentals, or anyone who wants
